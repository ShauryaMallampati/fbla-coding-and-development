const path = require("path");
const fs = require("fs");
const dotenv = require("dotenv");
const { Client } = require("pg");

const isPlaceholder = (value) =>
  !value || value.toLowerCase().startsWith("your_");
const repoRoot = path.join(__dirname, "..");
const existingEnv = new Set(Object.keys(process.env));
const loadEnvFile = (filePath) => {
  if (!fs.existsSync(filePath)) return;
  const parsed = dotenv.parse(fs.readFileSync(filePath));
  for (const [key, value] of Object.entries(parsed)) {
    if (isPlaceholder(value)) continue;
    if (existingEnv.has(key)) continue;
    process.env[key] = value;
  }
};

loadEnvFile(path.join(repoRoot, ".env"));
loadEnvFile(path.join(repoRoot, ".env.local"));
const dbUrl = process.env.SUPABASE_DB_URL || process.env.DATABASE_URL;
if (isPlaceholder(dbUrl)) {
  console.error("Missing SUPABASE_DB_URL (or DATABASE_URL). Add it to .env.local.");
  console.error("Find it in Supabase: Project Settings -> Database -> Connection string.");
  process.exit(1);
}

const useSsl = !/(localhost|127\.0\.0\.1)/i.test(dbUrl);
const client = new Client({
  connectionString: dbUrl,
  ssl: useSsl ? { rejectUnauthorized: false } : false
});

const statements = [
  `create table if not exists public.items (
    id bigint generated by default as identity primary key,
    title text not null,
    category text,
    description text,
    location_found text not null,
    date_found date not null,
    finder_name text,
    finder_email text,
    photo_path text,
    status text default 'pending',
    ai_validation jsonb,
    created_at timestamptz default now(),
    updated_at timestamptz default now()
  );`,
  `create table if not exists public.claims (
    id bigint generated by default as identity primary key,
    item_id bigint references public.items(id) on delete cascade,
    claimant_name text not null,
    claimant_email text not null,
    details text,
    status text default 'new',
    created_at timestamptz default now(),
    updated_at timestamptz default now()
  );`,
  "create index if not exists items_status_idx on public.items(status);",
  "create index if not exists items_category_idx on public.items(category);",
  "create index if not exists items_location_idx on public.items(location_found);"
];

async function ensureSchema() {
  await client.connect();
  try {
    await client.query("begin");
    for (const statement of statements) {
      await client.query(statement);
    }
    await client.query("commit");
  } catch (err) {
    try {
      await client.query("rollback");
    } catch (rollbackErr) {
      console.error("Rollback failed:", rollbackErr);
    }
    throw err;
  }

  try {
    await client.query("notify pgrst, 'reload schema';");
  } catch (err) {
    console.warn("Schema cache reload failed. You can run: NOTIFY pgrst, 'reload schema';");
    console.warn(err.message);
  }

  const { rows } = await client.query(
    "select count(*)::int as items_count from public.items;"
  );
  console.log("Supabase schema ensured. Items count:", rows[0]?.items_count ?? 0);
}

ensureSchema()
  .catch((err) => {
    console.error("Supabase schema setup failed:", err.message);
    process.exit(1);
  })
  .finally(async () => {
    await client.end();
  });
